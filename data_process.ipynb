{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "824ce6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os, shutil, sys, time, tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "283e66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 準備資料夾路徑\n",
    "\n",
    "dirs = ['train', 'valid', 'test', 'source']  # source for temp process\n",
    "classes = ['0', '1', '2', '3', 'pp']   # pp for temp process\n",
    "for d in dirs:\n",
    "    try:\n",
    "        os.mkdir('datasets/{}'.format(d))\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    for c in classes:\n",
    "        try:\n",
    "            os.mkdir('datasets/{}/{}'.format(d, c))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# try:\n",
    "#     os.mkdir('datasets/source')\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "try:\n",
    "    os.mkdir('datasets/source_bak')\n",
    "except:\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145324fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ac34fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29560/29560 [00:16<00:00, 1773.33it/s]\n"
     ]
    }
   ],
   "source": [
    "## 把檔案從 to_ocr_print_to_img/output 各資料夾中全部複製到  'datasets/source - bak'\n",
    "\n",
    "data_source_path = 'C:\\\\develop\\\\annotation_tools\\\\to_ocr_print_to_img\\\\output\\\\*\\\\*\\\\*.jpg'\n",
    "target_path = 'datasets/source_bak'\n",
    "filelist = glob.glob(data_source_path)\n",
    "print(len(filelist))\n",
    "\n",
    "limit = None\n",
    "for f in tqdm.tqdm(filelist[:limit]):\n",
    "    shutil.copy(f, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49aa4d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29560/29560 [00:03<00:00, 8260.55it/s]\n"
     ]
    }
   ],
   "source": [
    "### remove filename space and special character\n",
    "\n",
    "target_path = 'datasets\\\\source_bak'\n",
    "filelist = glob.glob(os.path.join(target_path, '*.jpg'))\n",
    "print(len(filelist))\n",
    "\n",
    "for f in tqdm.tqdm(filelist):\n",
    "    fname = os.path.basename(f).split('.jpg')[0]\n",
    "    replace_list = ['[', ']', ' ', '(', ')', '【', '】', '.', ',', '《', '》', '、', '。', '「', '」', '『', '』', '-']\n",
    "    for x in replace_list:\n",
    "        fname = fname.replace(x, '')\n",
    "    os.rename(f, os.path.join(target_path, fname+'.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c0f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 說明 先將上一步的圖片用 尺寸 排序，就幾乎可以將同一類方向排一起，手動搬到對應的資料夾\n",
    "### 剩下(留下來的)的圖片，就是要執行下面的程式 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32415f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29560/29560 [00:30<00:00, 979.93it/s] \n"
     ]
    }
   ],
   "source": [
    "## !!!執行後圖片可能會被轉方向!!!\n",
    "# remove exif \n",
    "\n",
    "target_path = 'datasets/source_bak'\n",
    "filelist = glob.glob(os.path.join(target_path, '*.jpg'))\n",
    "print(len(filelist))\n",
    "\n",
    "for f in tqdm.tqdm(filelist):\n",
    "\timg = Image.open(f)\n",
    "\texif = img._getexif()\n",
    "\n",
    "\tif exif is not None:\n",
    "\t\tfor (tag, value) in exif.items():\n",
    "\t\t\tkey = TAGS.get(tag, tag)\n",
    "\t\t\t# print(key , ' = ' , str(value))\n",
    "\t\t\n",
    "\t\tdata = list(img.getdata())\n",
    "\t\timage_without_exif = Image.new(img.mode, img.size)\n",
    "\t\timage_without_exif.putdata(data)\n",
    "\t\timage_without_exif.save(f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a594d6a",
   "metadata": {},
   "source": [
    "# 上面的完成後，用眼睛確認實際方向並手動移動檔案到對應的 source/0,1,2,3 裡面\n",
    "# 全部用下方程式旋轉到正向，可以反覆執行(0不會執行)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b23e74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 34.32it/s]\n",
      "100%|██████████| 3866/3866 [03:01<00:00, 21.27it/s] \n"
     ]
    }
   ],
   "source": [
    "filelist = glob.glob('datasets/source/1/*.jpg')    # 原圖為向右，用程式左轉90度轉正\n",
    "for demo_file in tqdm.tqdm(filelist):\n",
    "    img = Image.open(demo_file)\n",
    "    img=img.rotate(90, expand = True)  # 90 left -90 right -180 upside-down\n",
    "    img.save(demo_file)\n",
    "    \n",
    "filelist = glob.glob('datasets/source/2/*.jpg')   # 原圖為向下，用程式轉180度轉正\n",
    "for demo_file in tqdm.tqdm(filelist):\n",
    "    img = Image.open(demo_file)\n",
    "    img=img.rotate(-180, expand = True)  # 90 left -90 right -180 upside-down\n",
    "    img.save(demo_file)\n",
    "    \n",
    "filelist = glob.glob('datasets/source/3/*.jpg')   # 原圖為向左，用程式右轉90度轉正\n",
    "for demo_file in tqdm.tqdm(filelist):\n",
    "    img = Image.open(demo_file)\n",
    "    img=img.rotate(-90, expand = True)  # 90 left -90 right -180 upside-down\n",
    "    img.save(demo_file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9637dc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29560/29560 [00:05<00:00, 5583.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# remove exif again\n",
    "def clearExifInfo(filelist):\n",
    "    for f in tqdm.tqdm(filelist):\n",
    "        img = Image.open(f)\n",
    "        exif = img._getexif()\n",
    "\n",
    "        if exif is not None:\n",
    "            for (tag, value) in exif.items():\n",
    "                key = TAGS.get(tag, tag)\n",
    "                print(key , ' = ' , str(value))\n",
    "            \n",
    "            data = list(img.getdata())\n",
    "            image_without_exif = Image.new(img.mode, img.size)\n",
    "            image_without_exif.putdata(data)\n",
    "            image_without_exif.save(f)\n",
    "\n",
    "filelist = glob.glob('datasets/source/*/*.jpg') \n",
    "clearExifInfo(filelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c6f286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25690/25690 [00:20<00:00, 1232.80it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 128.00it/s]\n",
      "100%|██████████| 3866/3866 [00:07<00:00, 542.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# 檢查好沒問題再搬 , (然後搬移到 pp 資料夾中，再做後續流程)\n",
    "for i in [0, 1, 2, 3]:\n",
    "    filelist = glob.glob('datasets/source/{}/*.jpg'.format(i))\n",
    "    for f in tqdm.tqdm(filelist):\n",
    "        try:\n",
    "            shutil.move(f, 'datasets/source/pp')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "858bb0da",
   "metadata": {},
   "source": [
    "# 搬到 source/pp 之後，再次清除 image exif (exten info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d604beb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29560/29560 [00:03<00:00, 7451.75it/s]\n"
     ]
    }
   ],
   "source": [
    "### 搬到 source/pp 之後，清除 image exif (exten info)\n",
    "\n",
    "def clearExifInfo(filelist):\n",
    "    for f in tqdm.tqdm(filelist):\n",
    "        img = Image.open(f)\n",
    "        exif = img._getexif()\n",
    "\n",
    "        if exif is not None:\n",
    "            for (tag, value) in exif.items():\n",
    "                key = TAGS.get(tag, tag)\n",
    "                print(key + ' = ' + str(value))\n",
    "            \n",
    "            data = list(img.getdata())\n",
    "            image_without_exif = Image.new(img.mode, img.size)\n",
    "            image_without_exif.putdata(data)\n",
    "            image_without_exif.save(f)\n",
    " \n",
    "filelist = glob.glob('datasets/source/pp/*.jpg')\n",
    "clearExifInfo(filelist)\n",
    "\n",
    "# filelist = glob.glob('datasets/source/others/*.jpg')\n",
    "# clearExifInfo(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd1d040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets/source/pp\\\\04OLAP_300_026.jpg', 'datasets/source/pp\\\\04OLAP_300_027.jpg', 'datasets/source/pp\\\\04OLAP_300_028.jpg', 'datasets/source/pp\\\\04OLAP_300_029.jpg', 'datasets/source/pp\\\\04OLAP_300_030.jpg', 'datasets/source/pp\\\\04OLAP_300_031.jpg', 'datasets/source/pp\\\\04OLAP_300_032.jpg', 'datasets/source/pp\\\\04OLAP_300_033.jpg', 'datasets/source/pp\\\\04OLAP_300_034.jpg', 'datasets/source/pp\\\\04OLAP_300_035.jpg']\n",
      "['datasets/source/pp\\\\04OLAP', 'datasets/source/pp\\\\04OLAP', 'datasets/source/pp\\\\04OLAP', 'datasets/source/pp\\\\04OLAP', 'datasets/source/pp\\\\04OLAP', 'datasets/source/pp\\\\04OLAP', 'datasets/source/pp\\\\04OLAP', 'datasets/source/pp\\\\04OLAP', 'datasets/source/pp\\\\04OLAP', 'datasets/source/pp\\\\04OLAP']\n",
      "264\n",
      "['datasets/source/pp\\\\fb231104095216', 'datasets/source/pp\\\\combinepdf', 'datasets/source/pp\\\\今周刊20230803第1389期羅智先的新霸略', 'datasets/source/pp\\\\hw1', 'datasets/source/pp\\\\數位時代202308第351期新台劇闖全球', 'datasets/source/pp\\\\agreement', 'datasets/source/pp\\\\人工智慧之相關法規國際發展趨勢與因應委託研究計畫結案報告', 'datasets/source/pp\\\\kkbox公開說明書', 'datasets/source/pp\\\\綠界6763TT20231106', 'datasets/source/pp\\\\謝銘元推薦閱讀_民生证券轻工制造行业“碳中和”专题报告：CCER重启在望，我国碳交易']\n",
      "train 200\n",
      "valid 50\n",
      "test_list 14\n"
     ]
    }
   ],
   "source": [
    "### 照設定比例拆分，搬到 train valid test 的 pp 裡面\n",
    "filelist = glob.glob('datasets/source/pp/*.jpg')\n",
    "filelist = filelist + glob.glob('datasets/source/others/*.jpg')   # 這裡把 others 也加進來\n",
    "print(filelist[100:110])\n",
    "new_filelist = [x[:-12] for x in filelist]   # _600_001.jpg -> 共12個字元\n",
    "print(new_filelist[100:110])\n",
    "distinct_filelist = list(set(new_filelist))\n",
    "print(len(distinct_filelist))\n",
    "print(distinct_filelist[10:20])\n",
    "\n",
    "# 同一份文件風格類似，所以用文件來分割，不用圖片(頁面)來分割，否則模型可能會學到文件風格，而不是頁面方向特徵\n",
    "train_list, test_list = train_test_split(distinct_filelist, test_size=0.05, shuffle=True)\n",
    "train, valid = train_test_split(train_list, test_size=0.2, shuffle=True)\n",
    "print('train', len(train))\n",
    "print('valid', len(valid))\n",
    "print('test_list', len(test_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40dd50a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:43<00:00,  4.55it/s]\n",
      "100%|██████████| 50/50 [00:14<00:00,  3.41it/s]\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.63it/s]\n"
     ]
    }
   ],
   "source": [
    "thislist = []\n",
    "for f in tqdm.tqdm(train):\n",
    "    thislist = glob.glob(f+'_*_*.jpg')\n",
    "    for ff in thislist:\n",
    "        shutil.copy(ff, 'datasets/train/pp')\n",
    "\n",
    "thislist = []    \n",
    "for f in tqdm.tqdm(valid):\n",
    "    thislist = glob.glob(f+'_*_*.jpg')\n",
    "    for ff in thislist:\n",
    "        shutil.copy(ff, 'datasets/valid/pp')\n",
    "\n",
    "thislist = []\n",
    "for f in tqdm.tqdm(test_list):\n",
    "    thislist = glob.glob(f+'_*_*.jpg')\n",
    "    for ff in thislist:\n",
    "        shutil.copy(ff, 'datasets/test/pp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03223e0f",
   "metadata": {},
   "source": [
    "# about 20 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8632820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1425/21107 [00:12<01:18, 249.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error datasets/train/pp\\101年度國民消費意識及消費行為調查_300_026.jpg\n",
      "error datasets/train/pp\\101年度國民消費意識及消費行為調查_300_055.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1921/21107 [00:18<02:39, 120.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error datasets/train/pp\\107年行政院網路購物消費者意識及行為調查_200_019.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 10193/21107 [01:48<02:17, 79.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error datasets/train/pp\\GRI2GeneralDisclosure2021TraditionalEnglish_600_042.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 12319/21107 [02:11<01:32, 94.82it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error datasets/train/pp\\REO藍精品餅乾檢驗報告_600_006.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 16395/21107 [02:53<00:43, 108.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error datasets/train/pp\\內文_400_069.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21107/21107 [03:47<00:00, 92.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmtree train pp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5789/5789 [01:00<00:00, 95.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmtree valid pp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2692/2692 [00:27<00:00, 98.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmtree test pp\n"
     ]
    }
   ],
   "source": [
    "# 要先搬到 train valid test 資料夾裡面的 0 1 2 3 (旋轉方向)之後，才能做 img_padding & img_resize\n",
    "# 大約要 20 分鐘\n",
    "\n",
    "dirs = ['train', 'valid', 'test']  # source for temp process\n",
    "\n",
    "for d in dirs:\n",
    "    filelist = glob.glob('datasets/{}/pp/*.jpg'.format(d))\n",
    "    i = 0\n",
    "    for demo_file in tqdm.tqdm(filelist):\n",
    "        try:\n",
    "            img = ''\n",
    "            img = Image.open(demo_file)\n",
    "            # 改成每張圖片只放一個方向 其餘方向不放\n",
    "            if i%4 == 0:\n",
    "                img.save('datasets/{}/0/{}'.format(d, demo_file.split('\\\\')[-1]))     # 0 for original\n",
    "            elif i%4 == 1:\n",
    "                img=img.rotate(-90, expand = True)\n",
    "                img.save('datasets/{}/1/{}'.format(d, demo_file.split('\\\\')[-1]))\n",
    "            elif i%4 == 2:\n",
    "                img=img.rotate(-180, expand = True)\n",
    "                img.save('datasets/{}/2/{}'.format(d, demo_file.split('\\\\')[-1]))\n",
    "            elif i%4 == 3:\n",
    "                img=img.rotate(90, expand = True)\n",
    "                img.save('datasets/{}/3/{}'.format(d, demo_file.split('\\\\')[-1]))\n",
    "            else:\n",
    "                pass\n",
    "            i+=1\n",
    "            # img1=img1.rotate(-90, expand = True)  # -90 right\n",
    "            # img1.save('datasets/{}/1/{}'.format(d, demo_file.split('\\\\')[-1]))     # 1 for right\n",
    "            # img2=img.copy()\n",
    "            # img2=img2.rotate(-180, expand = True)  # -180 upside-down\n",
    "            # img2.save('datasets/{}/2/{}'.format(d, demo_file.split('\\\\')[-1]))     # 2 for upside-down\n",
    "            # img3=img.copy()\n",
    "            # img3=img3.rotate(90, expand = True)  # 90 left\n",
    "            # img3.save('datasets/{}/3/{}'.format(d, demo_file.split('\\\\')[-1]))     # 3 for left\n",
    "        except:\n",
    "            print('error', demo_file)\n",
    "            pass\n",
    "                 \n",
    "    shutil.rmtree('datasets/{}/pp'.format(d))\n",
    "    print('rmtree {} pp'.format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7f55b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3788/3788 [00:02<00:00, 1332.15it/s]\n",
      "100%|██████████| 947/947 [00:00<00:00, 1278.77it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 1264.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# 再做一次 remove exif\n",
    "\n",
    "def clearExifInfo(filelist):\n",
    "    for f in tqdm.tqdm(filelist):\n",
    "        img = Image.open(f)\n",
    "        exif = img._getexif()\n",
    "\n",
    "        if exif is not None:\n",
    "            for (tag, value) in exif.items():\n",
    "                key = TAGS.get(tag, tag)\n",
    "                print(key + ' = ' + str(value))\n",
    "            \n",
    "            data = list(img.getdata())\n",
    "            image_without_exif = Image.new(img.mode, img.size)\n",
    "            image_without_exif.putdata(data)\n",
    "            image_without_exif.save(f)\n",
    " \n",
    "filelist = glob.glob('datasets/train/*/*.jpg')\n",
    "clearExifInfo(filelist)\n",
    "\n",
    "filelist = glob.glob('datasets/valid/*/*.jpg')\n",
    "clearExifInfo(filelist)\n",
    "\n",
    "filelist = glob.glob('datasets/test/*/*.jpg')\n",
    "clearExifInfo(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ed4b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def cv2imread(img_path): \n",
    "    '''\n",
    "    處理 windows cv2 讀取中文檔名的問題\n",
    "    import cv2\n",
    "    '''\n",
    "    return cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_UNCHANGED)   # 保留色彩\n",
    "\n",
    "def img_padding(img):\n",
    "    h, w = img.shape[:2]\n",
    "    if h > w:\n",
    "        img = cv2.copyMakeBorder(img, 0, 0, 0, h-w, cv2.BORDER_CONSTANT, value=(128,128,128))   # top, bottom, left, right\n",
    "    elif w > h:\n",
    "        img = cv2.copyMakeBorder(img, 0, w-h, 0, 0, cv2.BORDER_CONSTANT, value=(128,128,128))\n",
    "    return img\n",
    "\n",
    "\n",
    "def img_preprocess(img_path, d, t, name):\n",
    "    # five_crop\n",
    "    n = name.split('\\\\')[-1][:-4] # 取檔名 去掉 .jpg\n",
    "    img = Image.open(img_path)\n",
    "    cs = TF.five_crop(img, 400)\n",
    "    sz = 224\n",
    "    for i, c in enumerate(cs):\n",
    "        c = TF.resize(c, (sz,sz))\n",
    "        c.save('datasets/{}/{}/{}_{}.jpg'.format(d, t, n, i))\n",
    "  \n",
    "    \n",
    "def img_resize_only(img_path, d, t, name): # add padding\n",
    "    '''\n",
    "    img : img path str\n",
    "    path : train, valid, test\n",
    "    name : img path str\n",
    "    '''\n",
    "    n = name.split('\\\\')[-1][:-4] # 取檔名 去掉 .jpg\n",
    "    img = cv2imread(img_path)\n",
    "    img = img_padding(img)\n",
    "    img = Image.fromarray(img)    \n",
    "    sz = 224\n",
    "    ss = TF.resize(img, (sz,sz))\n",
    "    ss.save('datasets/{}/{}/{}.jpg'.format(d, t, n))   # 覆蓋原檔案     \n",
    "\n",
    "print('ok')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea951b",
   "metadata": {},
   "source": [
    "# 這就真的非常久了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d4f5b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5276/5276 [02:35<00:00, 33.99it/s]\n",
      "100%|██████████| 5275/5275 [02:23<00:00, 36.85it/s]\n",
      "100%|██████████| 5275/5275 [02:22<00:00, 37.04it/s]\n",
      "100%|██████████| 5275/5275 [03:19<00:00, 26.43it/s]\n",
      "100%|██████████| 1448/1448 [00:59<00:00, 24.14it/s]\n",
      "100%|██████████| 1447/1447 [00:58<00:00, 24.71it/s] \n",
      "100%|██████████| 1447/1447 [00:24<00:00, 57.96it/s] \n",
      "100%|██████████| 1447/1447 [00:25<00:00, 56.24it/s] \n",
      "100%|██████████| 673/673 [00:11<00:00, 57.05it/s]\n",
      "100%|██████████| 673/673 [00:12<00:00, 54.56it/s] \n",
      "100%|██████████| 673/673 [00:12<00:00, 55.69it/s]\n",
      "100%|██████████| 673/673 [00:12<00:00, 53.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dirs = ['train', 'valid', 'test']\n",
    "types = ['0', '1', '2', '3']\n",
    "count = 0\n",
    "for d in dirs:\n",
    "    if d == 'train':  # only train do five_crop\n",
    "        for t in types:\n",
    "            filelist = glob.glob('datasets/' + d + '/' + t + '/*.jpg')\n",
    "            for f in tqdm.tqdm(filelist):\n",
    "                # five_crop\n",
    "                img_preprocess(f, d, t, f)\n",
    "                img_resize_only(f, d, t, f)\n",
    "                count += 1\n",
    "    else:\n",
    "        for t in types:\n",
    "            filelist = glob.glob('datasets/' + d + '/' + t + '/*.jpg')\n",
    "            for f in tqdm.tqdm(filelist):\n",
    "                img_resize_only(f, d, t, f)\n",
    "                count += 1\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a045b5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45de25f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135087\n"
     ]
    }
   ],
   "source": [
    "# 計算全部多少張圖片\n",
    "count = 0\n",
    "dirs = ['train', 'valid', 'test']\n",
    "for d in dirs:\n",
    "    filelist = glob.glob('datasets/' + d + '/*/*.jpg')\n",
    "    count += len(filelist)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c8654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9e1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f528c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epub to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e59f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c28d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
